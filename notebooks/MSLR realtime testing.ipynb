{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b86149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import cv2 \n",
    "from tensorflow.keras.models import load_model\n",
    "import traceback\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2bbd4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gradio==3.44.4\n",
    "# !pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f639d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio version: 3.44.4\n",
      "TensorFlow version: 2.13.0\n",
      "NumPy version: 1.22.4\n",
      "MediaPipe version: 0.10.5\n",
      "OpenCV version: 4.8.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradio version:\", gr.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"MediaPipe version:\", mp.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3157c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio version: 3.44.4\n",
      "TensorFlow version: 2.13.0\n",
      "NumPy version: 1.22.4\n",
      "MediaPipe version: 0.10.5\n",
      "OpenCV version: 4.8.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Gradio version:\", gr.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"MediaPipe version:\", mp.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24913a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.array(['မင်္ဂလာပါ','နေကောင်းလား', 'အဆင်ပြေတယ်','တနင်္လာ','အင်္ဂါ','ဗုဒ္ဓဟူး','ကြာသပတေး','သောကြာ','စနေ','တနင်္ဂနွေ'])\n",
    "model = load_model('0-9_50Frame_LSTM',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d04dd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities\n",
    "\n",
    "empty_frame = np.zeros((480, 480, 3))\n",
    "predictions_list=[]\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57fd2d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a30f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*3)\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([face, lh, pose, rh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cad123fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_video(video):\n",
    "    \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        sequence = []\n",
    "        mean_sequence=[]\n",
    "                    \n",
    "        cap = cv2.VideoCapture(video)\n",
    "        for frame_num in range(1,151):\n",
    "            ret, frame = cap.read()\n",
    "            if ret == False or (np.array_equal(empty_frame, frame)):\n",
    "                frame = last_frame    \n",
    "            img_resize = cv2.resize(frame, (512, 512))        \n",
    "            image, results = mediapipe_detection(img_resize, holistic)      \n",
    "            if results.face_landmarks:\n",
    "                keypoints = extract_keypoints(results)\n",
    "                sequence.append(keypoints)\n",
    "                if len(sequence) == 3:             \n",
    "                    mean_sequence.append(np.mean(sequence, axis=0))\n",
    "                    sequence=[]\n",
    "                                \n",
    "                                \n",
    "                if len(mean_sequence) == 50:\n",
    "                    res = model.predict(np.expand_dims(mean_sequence, axis=0))\n",
    "                    confidences=res[0]\n",
    "                    \n",
    "                    predicted_class = np.argmax(confidences)\n",
    "                    confidence = float(confidences[predicted_class])\n",
    "                    if confidence > threshold:\n",
    "                        sentence=str(words[predicted_class])\n",
    "                        confidences1 = {words[i]: float(confidences[i]) for i in range(10)}\n",
    "                    \n",
    "                \n",
    "                    \n",
    "                    \n",
    "            last_frame = frame\n",
    "            \n",
    "    return confidences1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c99c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(video_file):\n",
    "    try:\n",
    "        confidences1 = classify_video(video_file)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        return \"Prediction failed\"\n",
    "    return  confidences1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aed9878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_18412\\4161967978.py:3: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  inputs=gr.inputs.Video(),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_18412\\4161967978.py:3: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  inputs=gr.inputs.Video(),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_18412\\4161967978.py:6: GradioDeprecationWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  gr.outputs.Label(num_top_classes=3),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_18412\\4161967978.py:6: GradioUnusedKwargWarning: You have unused kwarg parameters in Label, please remove them: {'type': 'auto'}\n",
      "  gr.outputs.Label(num_top_classes=3),\n"
     ]
    }
   ],
   "source": [
    "iface = gr.Interface(\n",
    "  fn=predict,\n",
    "  inputs=gr.inputs.Video(),\n",
    "  outputs=[\n",
    "    \n",
    "    gr.outputs.Label(num_top_classes=3),\n",
    "  ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322a52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iface.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1124a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
